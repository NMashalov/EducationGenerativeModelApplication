Вероятностные графовые модели позволяют описать модель явления, используя связь случайных величин.


Отметим, что в отличие от классического подхода, в котором параметрические модели $f(x,\theta)$, не имеют заданного
вероятностного распределения, байесов вывод требует задания априорного распределения на $\theta$ :
\begin{equation}
    P(\theta | X) = \frac{P(X| \theta|) P(\theta)}{P(X)}
\end{equation}

, разделены на два основных класса: марковские случайные поля и байесовы сети.
Принципиальным отличием является наличие ориентированных ребер.








