Вероятностные графовые модели позволяют описать модель явления через
связь случайных величин.





Отметим, также что В отличие от классического подхода, в котором
параметрические модели $f(x,\theta)$, не имеют заданного
вероятностного распределения, байесов вывод
требует задания априорного распределения на $\theta$ :
\begin{equation}
    P(\theta | X) = \frac{P(X| \theta|) P(\theta)}{P(X)}
\end{equation}





, разделены на два основных класса: марковские случайные поля и байесовы сети.
Принципиальным отличием является наличие ориентированных ребер.








