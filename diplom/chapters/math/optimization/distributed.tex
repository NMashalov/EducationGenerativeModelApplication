Существенным препятствием к обучению больших моделей является распределение структурированных данных по множеству
локальных устройств, в условиях ограничения доступа к ним по соображениям приватности. Подобные постановки часто встречаются
при обучение в сфере медицины. Для ее разрешения вводятся алгоритмы распределенного обучения, эффективно использующие
локальные ресурсы и обменивающиеся между устройствами защищенными пакетами данных. Принципиально постановка задачи
заключается в определении порядка локальных и глобальных пересчетов с оптимальным уровнем компрессии при передаче данных.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{assets/math/distributed/distributed.excalidraw.png}
    \caption{Распределенное обучение включает локальные и глобальные ресурсы разделяемые раундами коммуникации }
    \label{distributed}
\end{figure}

Определим виды распределенного обучения:
 \begin{itemize}
    \item кластерное --- единая организация с доверенными узлами;
    \item коллаборативное --- добровольное присоединение к процессу обучения с возможностью покинуть 
          вычисление в любой момент времени;
    \item федеративное --- на устройствах пользователей с применением локальных вычислительных мощностей.
\end{itemize}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{assets/math/distributed/ring.excalidraw.png}
    \caption{Одной из распространенных архитектур взаимодействия между вычислительными узлами является кольцевая.}
    \label{ring}
\end{figure}

Ключевыми вопросами для разработки алгоритма являются определения следующих характеристик:
 \begin{itemize}
    \item числа пересчетов на вычислительных узлах $N$;
    \item объема коммуникаций при вычислениях $K$;
    \item степени компрессии данных при коммуникациях $\beta$.
\end{itemize}
    
\textit{Определение:} \textbf{Несмещенной компрессией} называется компрессия $\Pi$ со свойствами 
\begin{itemize}
    \item $\mathbb{E}[\Pi(x)] = x$
    \item $\mathbb{E}[\|\Pi(x)\|^2_2] \le \omega \| x \|^2_2$, где $\omega \ge 1$
\end{itemize}

Рассмотрим современные подходы к компрессии в постановке распределенных систем. 
\textit{Определение:} \textbf{Случайной спарсификацией} \cite{richtarik2016parallel} называется оператор, 
выбирающий из вектора компоненты по правилу:
\begin{equation}
    \text{Rankd}(x) = \frac{d}{k} \sum_{i \in S} x_i e_i,
\end{equation}
где $i$ --- случайно выбранные компоненты из базиса.

\textit{Определение:} \textbf{Трехуровневая} $\mathcal{l}_2$ квантизация задается оператором
$Q(x)=\|x\|_2 \text{sign}(x)\xi_i$, $i=1,\dots,d$  и $xi_i$ --- бернулевская случайная величина с параметром,
определяемым вкладом компоненты в модуль $\frac{|x_i|}{\|x\|_2}$.

\textit{Определение:} Пусть $\text{round}_\nu^-$ оператор, округляющий число до ближайшей степени $\nu \in \mathcal{N}$ снизу, 
$\text{round}_\nu^+$ --- аналогичный оператор для округления в большую сторону. Тогда \textbf{Натуральная компрессия} 
задается оператором:
\begin{equation}
    \text{Nat}(x)_i = \left\{\begin{array}{c}
        \text{round}_2^-(x_i), \ \text{c вероятностью} p=\frac{x_i - \text{round}_2^-(x)}{\text{round}_2^+(x)-\text{round}_2^-(x)} \\
        \text{round}_2^+(x_i) \\
    \end{array}\right.    
\end{equation}

\textit{Теорема:}\cite{stich2019unified} Если все функции $f_m$ являются $\mu$-сильно выпуклыми
и имеют $L$-липшицев градиент, тогда при шаге $\eta \le L^{-1} (\frac{2 \omega}{M}+1)^{-1}$:
\begin{equation}
    \mathcal{O}\left(
        (1-\gamma \mu)^K \|x_0 -x^*\|^2 + \frac{1}{K} \frac{2 \omega}{\mu M^2} \sum_{m=1}^M \| \nabla f_m(x^*) \|^2
    \right)
\end{equation}

Достижение единого согласованного состояния в распределенных системах обеспечивается с помощью специализированных алгоритмов  
Raft \cite{lamport2019time} и Paxos \cite{pease1980reaching}. 
В основе моделей лежит акторное (actor) разделение, позволяющее распределять данные между вычислительными узлами для обеспечения их 
сохранности и согласованности. 

\textit{Определение:}\textbf{Консенсус} является результатом достижения согласованного состояния между несколькими независимыми 
процессами или узлами в системе, которые могут взаимодействовать друг с другом. 

Для достижения консенсуса необходимо выполнить условия:
 \begin{enumerate}
    \item корректности: $\forall i \in \{1, \ldots, n\}, \text{если } \text{input}(N_i) = v, \text{ то } \forall j \in \{1, \ldots, n\}, \text{output}(N_j) = v$.
     Если все узлы начинают с одним и тем же начальным значением v, то любое значение, принятое в результате 
     выполнения протокола консенсуса, должно быть равно \( v \);
    \item единогласие: $\forall i, j \in \{1, \ldots, n\}, \text{если } \text{output}(N_i) = v, \text{ то } \text{output}(N_j) = v$.
     Если один узел завершает протокол с некоторым значением \( v \), то все другие узлы, которые также завершили протокол,
     должны иметь идентичное значение \( v \);
    \item завершение: $\forall i \in \{1, \ldots, n\}, \text{ узел } N_i$ 
    завершает выполнение протокола в конечное время.
\end{enumerate}


