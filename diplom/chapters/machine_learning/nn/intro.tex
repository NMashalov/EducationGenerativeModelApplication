Изначально искусственные нейронные сети строились как модель коры головного мозга человека. 
В отличие от своего биологического аналога нейронная сеть, как правило, имеет дифференцируемые функции 
активации, необходимые для эффективного обучения в ходе обратного распространения ошибки.

\textit{Определение} \textbf{Функцией активации} в нейронной сети называется \textit{нелинейная} функция,
связывающая выходной сигнал и активацию нейрона. 

На практике широко используются функции активации в виде сигмоидов $\sigma$, ReLU \cite{agarap2018deep} и 
GeLU \cite{hendrycks2016gaussian}

\begin{equation}
  \begin{aligned}
    & \sigma(x) = \frac{1}{1+\exp(-x)} \\
    &\text{ReLU}(x) = \min(0,x)p \\
    &\text{Tanh}(x) = \frac{e^{z}-e^{-z}}{e^{z}+e^{-z}} \\
    &\text{Gelu}(x) = \sigma(x) x 
  \end{aligned}
\end{equation}

Функция активации вводится для добавления нелинейности в модель, что позволяет нейронной сети моделировать сложные 
нелинейные зависимости в данных. Некоторые из распространенных функций активации включают в себя сигмоидальную 
функцию (\( \sigma \)), гиперболический тангенс (\( \tanh \)), ReLU (Rectified Linear Unit) и их вариации.

\textit{Определение} Перцептроном называется параметрическая математическая модель нейрона. Перцептрон
задается матрицей весов $W$, смещением $b$ и функцией активации $\sigma$
\begin{equation}
  \mathbf{y} = \sigma(W \mathbf{x} + \vec{b}),
\end{equation}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\textwidth]{assets/ml/nn/perceptron.excalidraw.png}
  \caption{Прямой процесс наложения шума и обратный процесс коррекции ошибки \cite{stablediffusion}}
  \label{perceptron}
\end{figure}

\textit{Определение} \textbf{Нейронные сети} параметрическая аппроксимирующая модель, состоящая из слоев нейронов.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\textwidth]{assets/ml/nn/nn.excalidraw.png}
  \caption{Преобразование сигнала выполняется в промежуточных слоях активации в ходе прямого распространения сигнала}
  \label{neural_net}
\end{figure}

В случае многослойной нейронной сети, выходы нейронов одного слоя становятся входами для следующего слоя, 
образуя цепочку преобразований. Процесс распространения через нейроны последовательных слоев называется 
прямым распространением (forward propagation).

Во время обучения модель минимизирует функцию потерь \( L \), которая оценивает разницу между предсказанным 
результатом $y_i$и истинным значением $y_i$:
\begin{equation}
  L = \frac{1}{N} \sum_{i=1}^{N} L(y_i, \hat{y}_i),
\end{equation}

Обучение нейронной сети выполняется путем настройки весов \( \mathbf{w} \) и смещений \( b \) 
с использованием алгоритмов оптимизации, таких как градиентный спуск \ref{}. 
