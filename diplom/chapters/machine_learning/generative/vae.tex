\textit{Определение } \textbf{Авторегрессионные модели} представляют собой класс порождающих моделей,
с вычислимой  вероятностью, выполняющие генерацию через цепочку последовательных преобразований \begin{equation}
    p(x^{(1)},\dots,x^{(t)}) = \prod_{t=1}^T p(x^{(t)}|x^{(1)},\dots,x^{(t-1)})
\end{equation}
Авторегрессионные модели могут быть реализованы с использованием различных подходов, 
включая марковские модели, рекуррентные нейронные сети и модели с авторегрессионными свойствами, такие как GPT (Generative Pre-trained Transformer) и LSTM (Long Short-Term Memory). 
Они находят применение в широком спектре задач обработки естественного языка, включая генерацию текста, машинный перевод, синтез речи и другие.

\begin{equation}
    \mathrm E_{p(\mathbf{x})} f(\mathbf{x}) = \int p(\mathbf{x}) f(\mathbf{x}) dx \approx \frac{1}{n} \sum_i=1^n f(x_i)
\end{equation}

\textit{Определение } \textbf{Модели потоков} называют генеративные модели основанные 
на последовательных обратимых дифференцируемых преобразованиях.
\begin{equation}
    \log p_{K}(z_K) = \log p_0(z_0) - \sum_{i=1}^K \log \left|\det \frac{d f_i(z_{i-1})}{d z_{i-1}} \right| 
\end{equation}

Ключевым для постановки является простота вычисления логарифма детерминанта и его невырожденность.