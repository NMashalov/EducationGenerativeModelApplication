Текущий популярный среди исследователей класс диффузионных порождающие 
моделей \cite{song2020score}, основан на энергетическом подходе. 
Ключевым преимуществом такой модели является возможность генерации 
элементов изучаемого распределения без потребности в его маргинализации.

\textit{Определение} \textbf{Энергетическими} подходы в машинном обучении 
называют класс статистических моделей, параметризующих вероятность 
состояния согласно энергии $E$:
\begin{equation}
    p(x) \sim \frac{\exp(-x)}{Z},
\end{equation}
где $Z=\int \exp(-x)$. 


Адаптация модели происходит через задачу оптимизации \cite{lecun2006tutorial}.
В ходе градиентного спуска происходит поиск минимума энергии реальных данных.

Пусть \( \mathbf{x} \) — наблюдаемая переменная (например, вектор признаков),
 а \( E(\mathbf{x}; \theta) \) — энергия, присвоенная данным \( \mathbf{x} \) моделью с параметрами \( \theta \). 

Обучение energy-based моделей часто включает минимизацию функции потерь, которая может быть определена как разница между энергией реальных данных и сгенерированных данных. Один из часто используемых подходов - это минимизация отклонения (discrepancy) между энергиями реальных данных \( \mathbf{x} \) и сгенерированных данных \( \tilde{\mathbf{x}} \):

\[ L(\theta) = E(\mathbf{x}; \theta) - E(\tilde{\mathbf{x}}; \theta) \]

Такой подход позволяет модели стремиться к минимизации энергии для реальных данных и максимизации энергии для сгенерированных данных.

Energy-based подходы имеют широкий спектр применений и используются в различных областях, включая глубокое обучение, генеративные модели и обучение без учителя. Они представляют собой мощный инструмент для моделирования данных с использованием концепции энергии, что позволяет справляться с различными задачами в машинном обучении.


\textit{Определение} \textbf{Диффузионные модели} \label{diffusion} представляют собой класс вероятностных моделей, 
использующих уравнение Ланжевена \ref{la} для генерации элементов $x$ из вероятного распределения $p$.

Диффузионных модели выполняют генерация последовательными шагами, заключающимися 
в последовательном исправление ошибок из начального изображения. 
Обучение исправлению ошибок выполняется путем предсказания шума между текущим и предыдущим шагом.

Прямым процессом диффузионной модели называется 
постепенное зашумление:\begin{equation}
    x_t = \sqrt{1-\beta_t} x_{t-1} + \sqrt{\beta_t} z_t,
\end{equation}
где $z_t \sim \mathcal{N}(0,\mathbf{I})$. Тогда итоговое 
вероятностное распределение запишется как:
\begin{equation}
    q(x_{T}) = q(x_0)q(x_1|x_0) \dots q(x_T|x_{T-1}) =
    q(x_0) \mathcal{N}(x_1|\sqrt{1-\beta_t}x_0,\beta_1I)\dots
    \mathcal{N}(x_T|\sqrt{1-\beta_T}x_0,\beta_TI)
\end{equation}
В компактной форме:
\begin{equation}
    ln q(x_{T}) = ln q(x_0) - \sum_{t=1}^T \frac{1}{2\beta_t} \| x_t - \sqrt{1-\beta_t} x_{t-1} \|^2 + C
\end{equation}

Обратный процесс заключается в составлении цепочки 
$\mathcal{N}(x_{t-1}|\mu(x_t,t),\Sigma(x_t,t))$ восстанавливающей элемент из шума:
\begin{equation}
    \begin{aligned}
        p_\theta(x_T) = \mathcal{N}(x_T|0,I);
        p_\theta(x_{t-1}|x_t) = \mathcal{N}(x_{t-1}|\mu_\theta(x_t,t), \Sigma_\theta(x_t,t))
    \end{aligned}
\end{equation}

Для введения параметрической модели используем нижнюю вариационную границу ELBO:
\begin{equation}
    \mathbb{E}_{x_0 \sim q} \ln p_\theta(x_0) \ge \mathrm{E} \ln p_\theta(x_T) - ln()
\end{equation}
Тогда функция ошибки запишется как:\begin{equation}
    \begin{aligned}
        &L(\theta) = - \sum_{t=1}^T\mathbb{E}_{x_{t-1},x_t \sim q} \left[-ln p_\theta(x_{t-1|x_t}\right] + \\
        &+ \mathbb{E}_{x_0 \sim q} \mathbf{D}_{KL}(q(x_T|x_0) \parallel p_\theta (x_T))
    \end{aligned}
\end{equation}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{assets/ml/generation/diffusion_1.excalidraw.png}
    \includegraphics[width=0.5\textwidth]{assets/ml/generation/diffusion_2.excalidraw.png}
    \caption{Прямой процесс зашумления и обратный процесс коррекции ошибки \cite{stablediffusion}}
    \label{sd_arch}
\end{figure}

На практике функция ошибки упрощается до предсказания шума:
\begin{equation}
    \mathrm{E}_{x_0 \sim q; z\sim \mathcal{N}(0,I)} 
    \left[ \| \varepsilon_\theta(x_t,t) -z \|^2\right]
\end{equation}


