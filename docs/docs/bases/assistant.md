---
title: Ассистенты
sidebar_position: 3
---



Успехи в области обработки и генерации естественного языка позволили расширить возможности виртуальных ассистентов по решению повседневных и деловых задач. В основе ассистента лежит языковая модель, обученная посредством техник оптимизации воспроизводить язык.


## Чат-боты

:::note

    Чат-бот - прикладное программное обеспечение, выполняющее задачи пользователя, согласно командам на естественном языке. 

:::

Как правило чат-ботов разделяют по их применению:
- **разговорный чат-бот** не имеет заранее заданной задачи и общается с пользователей для поддержания беседы
- **деловой чат-бот** направлен на решение конкретной задачи


## Формальная 

Статистическая формулировка языковой модели задается через цепи Маркова:

$$
    P(\omega_1, \dots, \omega_n) = P(\omega_n| \omega_1, \dots, \omega_{n-1}) \times \dots P(\omega_2 | \omega_1) \times P(\omega_1)
$$

, где $\omega_1, \dots, \omega_n$ - последовательность слов в предложении. Обуславливающие переменные называют контекстом $(.|\omega_1, \dots, \omega_{n-1}) $. Принципиально обучении языковой модели заключается в максимизации заданной вероятности при условии контекста для заданного текстового корпуса.

Поскольку длина последовательности может быть велика задача является высокоразмерной и потому не решается эмпирически через подсчет слов. Для решения используется аппроксимация с использованием нейросетей, выполняющие 


:::note

    Нейронная сеть - математическая модель. Функция активации нейрона задается через $f(x)=\sigma(\sum_{i=1}^n \omega_i x_i - \theta)$. Коэффициенты $w_i$ - называют весами перцептрона. Они служат формой памяти, того как правильно реагировать на входной сигнал.

:::


<img alt='Перцептрон' src='/img/perceptron.excalidraw.png'/>

### Механизм внимания

Механизм multihead attention был описан в известноц статьей ["Attention is all you need"](https://papers.nips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf). Attention рассчитывается как:

$$
    Attention = \softmax(\frac{\frac{QK^}{d_k}}V)
$$,

где $Q$, $K$ и $V$ рассчитываются с помощью отдельных нейростей, находящихся в блоке.

Выделяют механизмы self и cross attention.


### Большая языковая модель 

Большая языковая модель - это языковая модель как правило имеющая количество весов более миллиарда и использующая механизм Attention для обработки последовательностей.


Ассистенты, имеющие в основ  как ChatGPT помогают.


:::tip

    Ключевой особенностью больших языковых моделей является 
    - способность к запоминанию массивного числа языковых конструкций и их эмоциональных оттенков
    - приходить к несложным эвристическим заключениям

:::


## Применение в образовании

UNESCO регулярно публикует аналитические доклады https://www.unesco.org/en/digital-education/artificial-intelligence
Известны и применения [ассистентов для обучения русском языку](https://www.elibrary.ru/item.asp?id=36928343).







